{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Info**\n",
    "In this notebook, some preprocessing on the data has been done to prepare it for the naive estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Initialization**\n",
    "Here is where you load all the dependencies required for the good execution of (most of) the notebook. Here is where you load your libraries and instantiate your functions/classes. Here is where you load the data/models/pipelines that are going to be used in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 Loading libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time, datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BPI_Challenge_2012-training.csv')\n",
    "test = pd.read_csv('BPI_Challenge_2012-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2.1 - 2.2.5 Functions concerning time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month(x):\n",
    "    \"\"\"Convert object to the month of year\n",
    "\n",
    "    Args:\n",
    "        x (str)\n",
    "\n",
    "    Returns:\n",
    "        DateTime object\n",
    "    \"\"\"\n",
    "    return x.month\n",
    "\n",
    "def day(x):\n",
    "    \"\"\"Convert object to the day of year\n",
    "\n",
    "    Args:\n",
    "        x (str)\n",
    "\n",
    "    Returns:\n",
    "        DateTime object\n",
    "    \"\"\"\n",
    "    return x.day\n",
    "\n",
    "def week(x):\n",
    "    \"\"\"Convert object to the week of year\n",
    "\n",
    "    Args:\n",
    "        x (str)\n",
    "\n",
    "    Returns:\n",
    "        DateTime object\n",
    "    \"\"\"\n",
    "    return x.week\n",
    "\n",
    "def day_week(x):\n",
    "    \"\"\"Convert object to the day of week\n",
    "\n",
    "    Args:\n",
    "        x (str)\n",
    "\n",
    "    Returns:\n",
    "        DateTime object\n",
    "    \"\"\"\n",
    "    return x.weekday()\n",
    "\n",
    "def time_of_day(x):\n",
    "    \"\"\"Convert object to the hour of the day\n",
    "\n",
    "    Args:\n",
    "        x (str)\n",
    "\n",
    "    Returns:\n",
    "        DateTime object\n",
    "    \"\"\"\n",
    "    return x.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2.6 Function 'time_conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_conversion(dataframe):\n",
    "    \"\"\"Transform 'event time:timestamp' and 'case REG_DATE' from str to DateTime in a given Dataframe\n",
    "        Additionally, this function creates timestamps for the start and finish of a task in a seperate column. \n",
    "        The difference between these timestaps is the time to complete a task, which is also added to the dataframe.\n",
    "\n",
    "        Commented out lines are still for discussion\n",
    "        \n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): A pd.DataFrame in the format from the BPI_challenge 2012\n",
    "\n",
    "    Returns:\n",
    "        dataframe_output: A pd.DataFrame with all the strings reformatted to DateTime in the 'event time:timestamp' and 'case REG_DATE' columns\n",
    "    \"\"\"\n",
    "    \n",
    "#     dataframe.drop(columns = ['eventID '], inplace=True) # Drop eventID\n",
    "    dataframe.reset_index(inplace=True)\n",
    "    \n",
    "    #Transform 'event time:timestamp' and 'case REG_DATE' from str to DateTime  \n",
    "    dataframe['case REG_DATE'] =  pd.to_datetime(dataframe['case REG_DATE'])\n",
    "    dataframe['event time:timestamp'] =  pd.to_datetime(dataframe['event time:timestamp'])\n",
    "    \n",
    "    #Creates timestamps for the start and finish of a task in a seperate column + the time to complete the task.\n",
    "    dataframe['timestamp_start'] = dataframe['case REG_DATE'].values.astype(np.int64) // 10 ** 9\n",
    "    dataframe['timestamp_finish'] = dataframe['event time:timestamp'].values.astype(np.int64) // 10 ** 9 \n",
    "#     dataframe['time_to_complete']= (dataframe[\"event time:timestamp\"] - dataframe[\"case REG_DATE\"])/10**6\n",
    "\n",
    "\n",
    "    # Convert the timestamps of the event time to day of week, specific day and time of that day.\n",
    "    \n",
    "    dataframe[\"day_week\"] = dataframe[\"event time:timestamp\"].apply(day_week)\n",
    "    # dataframe[\"week\"] = dataframe[\"event time:timestamp\"].apply(week)\n",
    "#     dataframe[\"day_month\"] = dataframe[\"event time:timestamp\"].apply(day)\n",
    "    # dataframe[\"month\"] = dataframe[\"event time:timestamp\"].apply(month)\n",
    "    dataframe['time_of_day'] = dataframe['event time:timestamp'].apply(time_of_day)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2.7 Function 'encoding'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(dataframe):\n",
    "    \"\"\"Encoding \n",
    "\n",
    "    What kind of encoding is this exactly?\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): A pd.DataFrame in the format from the BPI_challenge 2012\n",
    "\n",
    "    Returns:\n",
    "        dataframe: A pd.DataFrame with cases and events sorted wrt time, each event has a position within its case\n",
    "    \"\"\"\n",
    "    # sort cases wrt time, for each case sort events \n",
    "    dataframe.sort_values(['timestamp_start',\"timestamp_finish\"], axis=0, ascending=True, inplace=True, ignore_index=True)\n",
    "    \n",
    "    # assign the position in the sequence to each event\n",
    "    dataframe['position'] = None\n",
    "    dataframe['position'] = dataframe.groupby('case concept:name').cumcount() + 1\n",
    "    \n",
    "    \n",
    "    # create columns with previous and future (times of) events\n",
    "    df[\"prev_event\"] = df.groupby(\"case concept:name\")[\"event concept:name\"].shift(1)\n",
    "    df[\"2prev_event\"] = df.groupby(\"case concept:name\")[\"event concept:name\"].shift(2)\n",
    "    df[\"next_event\"] = df.groupby(\"case concept:name\")[\"event concept:name\"].shift(-1)\n",
    "\n",
    "    df[\"prev_time\"] = df.groupby(\"case concept:name\")[\"event time:timestamp\"].shift(1)\n",
    "    df[\"next_time\"] = df.groupby(\"case concept:name\")[\"event time:timestamp\"].shift(-1)\n",
    "    df[\"prev_timestamp\"] = df.groupby(\"case concept:name\")[\"timestamp_finish\"].shift(1)\n",
    "    df[\"next_timestamp\"] = df.groupby(\"case concept:name\")[\"timestamp_finish\"].shift(-1)\n",
    "\n",
    "    df[\"next_event\"].fillna(\"LAST EVENT\", inplace=True)\n",
    "    df[\"prev_event\"].fillna(\"FIRST EVENT\", inplace=True)\n",
    "    df[\"2prev_event\"].fillna(\"FIRST EVENT\", inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     these values should be empty and filling them equals creating wrong data, but otherwise models dont work :( \n",
    "    df[\"next_time\"].fillna(method='ffill', inplace=True)\n",
    "    df[\"prev_time\"].fillna(method='bfill', inplace=True)\n",
    "    df[\"next_timestamp\"].fillna(method='ffill', inplace=True)\n",
    "    df[\"prev_timestamp\"].fillna(method='bfill', inplace=True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2.x Function: 'preprocessing'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataframe):\n",
    "    \"\"\"Does all the processing needed for the naive estimator\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): A pd.DataFrame in the format from the BPI_challenge 2012\n",
    "    \"\"\"\n",
    "    pp_df = encoding(time_conversion(dataframe))\n",
    "    \n",
    "    \n",
    "    return pp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Preprocessing**\n",
    "Here a couple of things are preprocessed:\n",
    "- Time conversion (see function 2.2.6)\n",
    "- Encoding (See function 2.2.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Preprocessing and splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = preprocessing(df)\n",
    "# test = preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the data sets and preprocess\n",
    "df = pd.concat([df, test], axis=\"rows\", ignore_index=True)\n",
    "df = preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['index'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# a check for duplicate events, gives error if none repeat\n",
    "# pd.concat(g for _, g in df.groupby(\"eventID \") if len(g) > 1).tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:239787]\n",
    "test = df.iloc[239787:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 Export dataframe to .CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('preprocessed_train.csv')\n",
    "test.to_csv('preprocessed_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4 Results**\n",
    "Here is where you summarize all the results of the analysis as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An alternative to the used encoding might be one-hot-encoding. Downside of OHC is it can increase the dimensionality of the data, which can lead to overfitting or increased computation time. Furthermore it can waste memory space and therefore not computational optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8ecf3d1b7816c8a562bac795b7c2fee9a5e529b79bc3cd729516b279b05f6b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
